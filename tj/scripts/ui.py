"""
Gradio UI interface for OpenAI API compatibility demo.

Author: tj-scripts
Email: tangj1984@gmail.com
Date: 2024-03-21
"""

from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import gradio as gr
from .models.chat import ChatSession
from .config import config
from .utils.logger import setup_logger
from .api.openai import OpenAIClient

# Set up logging
logger = setup_logger(
    "tj.scripts",
    level=config.get("logging", "level", "INFO"),
    format=config.get("logging", "format", "%(asctime)s - %(name)s - %(levelname)s - %(message)s"),
    file=config.get("logging", "file", "app.log"),
    max_size=config.get("logging", "max_size", 10 * 1024 * 1024),  # 10MB
    backup_count=config.get("logging", "backup_count", 5)
)

# èŽ·å–èµ„æºç›®å½•è·¯å¾„
RESOURCE_DIR = Path(__file__).parent.parent / "resources"
AVATAR_DIR = RESOURCE_DIR / "avatars"

# ç¡®ä¿å¤´åƒç›®å½•å­˜åœ¨
AVATAR_DIR.mkdir(parents=True, exist_ok=True)

# é»˜è®¤å¤´åƒè·¯å¾„
USER_AVATAR = str(AVATAR_DIR / "user.png")
ASSISTANT_AVATAR = str(AVATAR_DIR / "assistant.png")

class ChatUI:
    """Chat UI class for managing the Gradio interface."""

    def __init__(self) -> None:
        """Initialize the chat UI."""
        try:
            self.chat_session: Optional[ChatSession] = None
            self.client: Optional[OpenAIClient] = None
            self.history: List[Tuple[str, str]] = []  # ä¿®æ”¹ä¸ºå…ƒç»„åˆ—è¡¨
            self.is_initialized = False
            logger.info("Chat UI initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize Chat UI: {e}")
            raise

    async def initialize_chat(self) -> None:
        """Initialize the chat session."""
        if self.is_initialized:
            return

        try:
            # èŽ·å– API é…ç½®
            api_config = config.get_section("api").get("siliconflow", {})
            if not api_config:
                raise ValueError("SiliconFlow API configuration not found")
            
            # åˆ›å»º OpenAI å®¢æˆ·ç«¯
            self.client = OpenAIClient(api_config)
            
            # åˆ›å»ºèŠå¤©ä¼šè¯
            self.chat_session = ChatSession(
                temperature=api_config.get("temperature", 0.7),
                max_tokens=api_config.get("max_tokens", 2000)
            )
            
            # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
            self.chat_session.add_message(
                role="system",
                content="You are a helpful AI assistant."
            )
            
            # æ·»åŠ æ¬¢è¿Žæ¶ˆæ¯
            welcome_message = (
                "Welcome to the AI Chat! I'm here to help you with any questions or tasks you have.\n\n"
                "Features:\n"
                "- Interactive chat interface\n"
                "- Chat history management\n"
                "- Configurable parameters\n"
                "- Error handling and retries\n\n"
                "Feel free to start chatting!"
            )
            
            # æ·»åŠ åŠ©æ‰‹çš„æ¬¢è¿Žæ¶ˆæ¯åˆ°åŽ†å²è®°å½•
            self.history.append(("", welcome_message))
            
            self.is_initialized = True
            logger.info("Chat session initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize chat session: {e}")
            self.is_initialized = False
            raise

    async def send_message(
        self,
        message: str,
        history: List[Tuple[str, str]],  # ä¿®æ”¹ä¸ºå…ƒç»„åˆ—è¡¨
        temperature: float = 0.7,
        max_tokens: int = 2000,
    ) -> Tuple[List[Tuple[str, str]], str]:  # ä¿®æ”¹ä¸ºå…ƒç»„åˆ—è¡¨
        """Send a message and get the response.

        Args:
            message: The message to send
            history: The chat history as list of (user_message, assistant_message) tuples
            temperature: The temperature for response generation
            max_tokens: The maximum number of tokens to generate

        Returns:
            Tuple containing:
            - The updated chat history as list of (user_message, assistant_message) tuples
            - Empty string to clear input
        """
        if not message.strip():
            return history, ""

        try:
            if not self.is_initialized:
                await self.initialize_chat()

            if not self.chat_session or not self.client:
                raise ValueError("Chat session or client not initialized")

            # æ›´æ–°èŠå¤©å‚æ•°
            self.chat_session.temperature = temperature
            self.chat_session.max_tokens = max_tokens

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            self.chat_session.add_message(
                role="user",
                content=message
            )

            # å‘é€è¯·æ±‚
            response = await self.client.chat_completion(
                messages=self.chat_session.get_messages(),
                temperature=temperature,
                max_tokens=max_tokens,
                stream=False
            )

            # èŽ·å–åŠ©æ‰‹å›žå¤
            assistant_message = response["choices"][0]["message"]["content"]

            # æ·»åŠ åŠ©æ‰‹å›žå¤
            self.chat_session.add_message(
                role="assistant",
                content=assistant_message
            )

            # æ›´æ–°åŽ†å²è®°å½•
            history.append((message, assistant_message))

            # è®°å½•æ—¥å¿—
            logger.info(f"User: {message}")
            logger.info(f"Assistant: {assistant_message}")

            return history, ""
        except Exception as e:
            error_msg = f"Error: {str(e)}"
            logger.error(f"Error sending message: {e}")
            history.append((message, error_msg))  # ä½¿ç”¨å…ƒç»„è€Œä¸æ˜¯å­—å…¸
            return history, ""

    def clear_history(self) -> List[Tuple[str, str]]:  # ä¿®æ”¹ä¸ºå…ƒç»„åˆ—è¡¨
        """Clear the chat history.

        Returns:
            Empty chat history as list of (user_message, assistant_message) tuples
        """
        if self.chat_session:
            self.chat_session.clear()
            # é‡æ–°æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
            self.chat_session.add_message(
                role="system",
                content="You are a helpful AI assistant."
            )
        self.history = []
        logger.info("Chat history cleared")
        return []

    def create_ui(self) -> gr.Blocks:
        """Create the Gradio UI interface.

        Returns:
            The Gradio interface
        """
        with gr.Blocks(title="OpenAI API Chat Demo", theme=gr.themes.Soft()) as interface:
            gr.Markdown(
                """
                # ðŸ¤– OpenAI API Chat Demo
                
                A demonstration of OpenAI API compatibility with interactive chat interface.
                
                ## Features
                - Support for OpenAI API and compatible services
                - Interactive chat interface
                - Chat history management
                - Configurable parameters
                - Error handling and retries
                """
            )

            with gr.Row():
                with gr.Column(scale=4):
                    chatbot = gr.Chatbot(
                        [],  # åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
                        elem_id="chatbot",
                        bubble_full_width=False,
                        avatar_images=(USER_AVATAR, ASSISTANT_AVATAR),  # ä½¿ç”¨å®žé™…å›¾ç‰‡æ–‡ä»¶
                        height=350,
                        show_label=False,
                    )
                    with gr.Row():
                        txt = gr.Textbox(
                            show_label=False,
                            placeholder="Type your message here...",
                            container=False,
                            lines=3,
                            max_lines=5,
                        )
                        submit_btn = gr.Button("Send", variant="primary")

                with gr.Column(scale=1):
                    with gr.Accordion("Parameters", open=False):
                        temperature = gr.Slider(
                            minimum=0.0,
                            maximum=1.0,
                            value=0.7,
                            step=0.1,
                            label="Temperature",
                            info="Controls randomness in the response",
                        )
                        max_tokens = gr.Slider(
                            minimum=100,
                            maximum=4000,
                            value=2000,
                            step=100,
                            label="Max Tokens",
                            info="Maximum number of tokens to generate",
                        )
                    with gr.Row():
                        clear_btn = gr.Button("Clear History", variant="secondary")
                        retry_btn = gr.Button("Retry Last Message", variant="secondary")

            # Event handlers
            submit_btn.click(
                self.send_message,
                [txt, chatbot, temperature, max_tokens],
                [chatbot, txt],
            )

            clear_btn.click(self.clear_history, None, [chatbot])

            # Enter key submission (Shift+Enter for new line)
            txt.submit(
                self.send_message,
                [txt, chatbot, temperature, max_tokens],
                [chatbot, txt],
            )

        return interface

def main() -> None:
    """Main entry point for the UI application."""
    try:
        chat_ui = ChatUI()
        interface = chat_ui.create_ui()
        interface.launch(
            server_name="127.0.0.1",
            server_port=7860,
            share=False,
            favicon_path="ðŸ¤–",  # ä½¿ç”¨ emoji ä½œä¸ºç½‘ç«™å›¾æ ‡
        )
    except Exception as e:
        logger.error(f"Failed to start UI: {e}")
        raise

if __name__ == "__main__":
    main() 